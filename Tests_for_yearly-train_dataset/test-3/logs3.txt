Beginning AutoGluon training... Time limit = 7200s
AutoGluon will save models to 'AutogluonModels\ag-20240429_091754'
=================== System Info ===================
AutoGluon Version:  1.0.0
Python Version:     3.10.13
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.90 GB / 5.92 GB (15.2%)
Disk Space Avail:   9.00 GB / 118.01 GB (7.6%)
	WARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. 
	We recommend a minimum available disk space of 10 GB, and large datasets may require more.
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': False,
 'eval_metric': MSE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 4,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'target': 'target',
 'time_limit': 7200,
 'val_step_size': 2,
 'verbosity': 2}

Inferred time series frequency: 'N'
Provided train_data has 720458 rows, 23000 time series. Median time series length is 29 (min=13, max=835). 
Time series in train_data are too short for chosen num_val_windows=4. Reducing num_val_windows to 1.
	Removing 22841 short time series from train_data. Only series with length >= 97 will be used for training.
	After removing short series, train_data has 37773 rows, 159 time series. Median time series length is 207 (min=97, max=835). 

Provided dataset contains following columns:
	target:           'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MSE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2024-04-29 12:17:55
Models that will be trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 1028.4s of the 7199.0s of remaining time.
	-8773909.3052 = Validation score (-MSE)
	0.08    s     = Training runtime
	10.84   s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 1198.0s of the 7188.1s of remaining time.
	-8773909.3052 = Validation score (-MSE)
	0.07    s     = Training runtime
	0.63    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 1437.5s of the 7187.3s of remaining time.
	-7975790.5389 = Validation score (-MSE)
	0.07    s     = Training runtime
	54.06   s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 1783.3s of the 7133.2s of remaining time.
	-8323944.8562 = Validation score (-MSE)
	0.07    s     = Training runtime
	24.77   s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 2369.4s of the 7108.3s of remaining time.
	-9753578.1910 = Validation score (-MSE)
	3.48    s     = Training runtime
	1.06    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 3551.9s of the 7103.8s of remaining time.
	-19266768.9761= Validation score (-MSE)
	0.94    s     = Training runtime
	0.37    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 7102.4s of the 7102.4s of remaining time.
	-7107845.5527 = Validation score (-MSE)
	6398.75 s     = Training runtime
	2.66    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer']
Total runtime: 6498.06 s
Best model: TemporalFusionTransformer
Best model score: -7107845.5527
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer