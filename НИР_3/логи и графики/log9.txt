Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'autogluon-m4-hourly'
=================== System Info ===================
AutoGluon Version:  1.0.0
Python Version:     3.10.13
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       1.07 GB / 5.92 GB (18.1%)
Disk Space Avail:   24.16 GB / 118.01 GB (20.5%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WAPE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'target': 'target',
 'time_limit': 600,
 'verbosity': 2}

Inferred time series frequency: 'H'
Provided train_data has 148060 rows, 200 time series. Median time series length is 700 (min=700, max=960). 

Provided dataset contains following columns:
	target:           'target'

AutoGluon will gauge predictive performance using evaluation metric: 'WAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2023-12-18 18:46:06
Models that will be trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 75.0s of the 599.8s of remaining time.
	-0.1656       = Validation score (-WAPE)
	0.18    s     = Training runtime
	6.96    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 84.7s of the 592.6s of remaining time.
	-0.0438       = Validation score (-WAPE)
	0.17    s     = Training runtime
	0.59    s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 98.6s of the 591.8s of remaining time.
	Time limit exceeded... Skipping ETS.
Training timeseries model Theta. Training for up to 98.5s of the 492.5s of remaining time.
	-0.0468       = Validation score (-WAPE)
	0.18    s     = Training runtime
	76.60   s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 103.9s of the 415.7s of remaining time.
	-0.0419       = Validation score (-WAPE)
	5.56    s     = Training runtime
	1.82    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 136.1s of the 408.2s of remaining time.
	-0.0525       = Validation score (-WAPE)
	16.89   s     = Training runtime
	1.19    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 195.0s of the 390.1s of remaining time.
	-0.0862       = Validation score (-WAPE)
	181.42  s     = Training runtime
	2.93    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'Naive': 0.09, 'RecursiveTabular': 0.89, 'Theta': 0.02}
	-0.0375       = Validation score (-WAPE)
	3.65    s     = Training runtime
	85.38   s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'Theta', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 398.03 s
Best model: WeightedEnsemble
Best model score: -0.0375
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble