Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'AutogluonModels\ag-20240424_043550'
=================== System Info ===================
AutoGluon Version:  1.0.0
Python Version:     3.10.13
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.79 GB / 5.92 GB (13.4%)
Disk Space Avail:   18.60 GB / 118.01 GB (15.8%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': False,
 'eval_metric': MAE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 4,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'target': 'target',
 'time_limit': 3600,
 'val_step_size': 2,
 'verbosity': 2}

Inferred time series frequency: 'QS-OCT'
Provided train_data has 2214108 rows, 24000 time series. Median time series length is 88 (min=16, max=866). 
Time series in train_data are too short for chosen num_val_windows=4. Reducing num_val_windows to 1.
	Removing 13678 short time series from train_data. Only series with length >= 97 will be used for training.
	After removing short series, train_data has 1359498 rows, 10322 time series. Median time series length is 118 (min=97, max=866). 

Provided dataset contains following columns:
	target:           'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2024-04-24 07:35:53
Models that will be trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 513.9s of the 3597.4s of remaining time.
	-1726.5189    = Validation score (-MAE)
	2.01    s     = Training runtime
	35.75   s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 593.2s of the 3559.5s of remaining time.
	-1792.9469    = Validation score (-MAE)
	2.08    s     = Training runtime
	34.38   s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 704.6s of the 3522.9s of remaining time.
	Time limit exceeded... Skipping ETS.
Training timeseries model Theta. Training for up to 704.3s of the 2817.3s of remaining time.
	-1584.3396    = Validation score (-MAE)
	1.72    s     = Training runtime
	172.06  s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 881.1s of the 2643.4s of remaining time.
	-1475.5786    = Validation score (-MAE)
	172.96  s     = Training runtime
	64.08   s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 1203.1s of the 2406.1s of remaining time.
	-2948.5081    = Validation score (-MAE)
	148.94  s     = Training runtime
	50.87   s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 2206.1s of the 2206.1s of remaining time.
	-1505.4424    = Validation score (-MAE)
	1991.03 s     = Training runtime
	96.01   s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'Theta', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer']
Total runtime: 3478.39 s
Best model: RecursiveTabular
Best model score: -1475.5786
Model not specified in predict, will default to the model with the best validation score: RecursiveTabular