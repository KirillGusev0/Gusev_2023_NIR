Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'AutogluonModels\ag-20240424_053915'
=================== System Info ===================
AutoGluon Version:  1.0.0
Python Version:     3.10.13
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.76 GB / 5.92 GB (12.9%)
Disk Space Avail:   18.02 GB / 118.01 GB (15.3%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': False,
 'eval_metric': MAPE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 4,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'target': 'target',
 'time_limit': 3600,
 'val_step_size': 2,
 'verbosity': 2}

Inferred time series frequency: 'QS-OCT'
Provided train_data has 2214108 rows, 24000 time series. Median time series length is 88 (min=16, max=866). 
Time series in train_data are too short for chosen num_val_windows=4. Reducing num_val_windows to 1.
	Removing 13678 short time series from train_data. Only series with length >= 97 will be used for training.
	After removing short series, train_data has 1359498 rows, 10322 time series. Median time series length is 118 (min=97, max=866). 

Provided dataset contains following columns:
	target:           'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2024-04-24 08:39:17
Models that will be trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 513.9s of the 3597.6s of remaining time.
	-0.3207       = Validation score (-MAPE)
	1.70    s     = Training runtime
	31.45   s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 594.0s of the 3564.3s of remaining time.
	-0.3272       = Validation score (-MAPE)
	1.87    s     = Training runtime
	22.71   s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 707.9s of the 3539.6s of remaining time.
	Time limit exceeded... Skipping ETS.
Training timeseries model Theta. Training for up to 707.7s of the 2830.9s of remaining time.
	-0.3033       = Validation score (-MAPE)
	3.75    s     = Training runtime
	223.86  s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 867.7s of the 2603.0s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	Trainer has no fit models that can infer.
Training timeseries model DirectTabular. Training for up to 1287.3s of the 2574.6s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Trainer has no fit models that can infer.
Training timeseries model TemporalFusionTransformer. Training for up to 2527.5s of the 2527.5s of remaining time.
	-0.3078       = Validation score (-MAPE)
	2281.94 s     = Training runtime
	91.38   s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'Theta', 'TemporalFusionTransformer']
Total runtime: 3443.55 s
Best model: Theta
Best model score: -0.3033
Model not specified in predict, will default to the model with the best validation score: Theta