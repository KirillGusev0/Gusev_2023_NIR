Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'AutogluonModels\ag-20240424_064435'
=================== System Info ===================
AutoGluon Version:  1.0.0
Python Version:     3.10.13
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.48 GB / 5.92 GB (8.2%)
Disk Space Avail:   17.15 GB / 118.01 GB (14.5%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': False,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 4,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'target': 'target',
 'time_limit': 3600,
 'val_step_size': 2,
 'verbosity': 2}

Inferred time series frequency: 'QS-OCT'
Provided train_data has 2214108 rows, 24000 time series. Median time series length is 88 (min=16, max=866). 
Time series in train_data are too short for chosen num_val_windows=4. Reducing num_val_windows to 1.
	Removing 13678 short time series from train_data. Only series with length >= 97 will be used for training.
	After removing short series, train_data has 1359498 rows, 10322 time series. Median time series length is 118 (min=97, max=866). 

Provided dataset contains following columns:
	target:           'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2024-04-24 09:44:38
Models that will be trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 513.9s of the 3597.1s of remaining time.
	-6.9018       = Validation score (-MASE)
	2.20    s     = Training runtime
	26.38   s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 594.7s of the 3568.4s of remaining time.
	-7.1919       = Validation score (-MASE)
	2.31    s     = Training runtime
	29.40   s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 707.3s of the 3536.6s of remaining time.
	Time limit exceeded... Skipping ETS.
Training timeseries model Theta. Training for up to 707.1s of the 2828.3s of remaining time.
	-6.0175       = Validation score (-MASE)
	2.05    s     = Training runtime
	168.44  s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 885.9s of the 2657.7s of remaining time.
	-5.2104       = Validation score (-MASE)
	170.53  s     = Training runtime
	61.64   s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 1212.7s of the 2425.4s of remaining time.
	-12.7996      = Validation score (-MASE)
	146.97  s     = Training runtime
	46.87   s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 2231.3s of the 2231.3s of remaining time.
	-5.4646       = Validation score (-MASE)
	2014.25 s     = Training runtime
	94.52   s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'Theta', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer']
Total runtime: 3474.67 s
Best model: RecursiveTabular
Best model score: -5.2104
Model not specified in predict, will default to the model with the best validation score: RecursiveTabular