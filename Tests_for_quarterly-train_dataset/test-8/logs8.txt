Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'AutogluonModels\ag-20240424_105058'
=================== System Info ===================
AutoGluon Version:  1.0.0
Python Version:     3.10.13
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.97 GB / 5.92 GB (16.4%)
Disk Space Avail:   15.22 GB / 118.01 GB (12.9%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': False,
 'eval_metric': SMAPE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'target': 'target',
 'time_limit': 3600,
 'val_step_size': 2,
 'verbosity': 2}

Inferred time series frequency: 'QS-OCT'
Provided train_data has 2214108 rows, 24000 time series. Median time series length is 88 (min=16, max=866). 
	Removing 13678 short time series from train_data. Only series with length >= 97 will be used for training.
	After removing short series, train_data has 1359498 rows, 10322 time series. Median time series length is 118 (min=97, max=866). 

Provided dataset contains following columns:
	target:           'target'

AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2024-04-24 13:51:01
Models that will be trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'RecursiveTabular', 'DirectTabular', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 513.9s of the 3597.4s of remaining time.
	-0.3324       = Validation score (-SMAPE)
	1.85    s     = Training runtime
	36.64   s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 593.1s of the 3558.8s of remaining time.
	-0.3497       = Validation score (-SMAPE)
	1.79    s     = Training runtime
	23.38   s     = Validation (prediction) runtime
Training timeseries model ETS. Training for up to 706.7s of the 3533.5s of remaining time.
	Time limit exceeded... Skipping ETS.
Training timeseries model Theta. Training for up to 706.5s of the 2825.9s of remaining time.
	-0.3115       = Validation score (-SMAPE)
	1.74    s     = Training runtime
	168.00  s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 885.3s of the 2655.9s of remaining time.
	-0.2741       = Validation score (-SMAPE)
	2113.44 s     = Training runtime
	335.32  s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 103.5s of the 207.0s of remaining time.
	Warning: Exception caused LightGBM to fail during training... Skipping this model.
		'NoneType' object is not iterable
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Trainer has no fit models that can infer.
Training timeseries model TemporalFusionTransformer. Training for up to 163.4s of the 163.4s of remaining time.
	-0.3549       = Validation score (-SMAPE)
	153.88  s     = Training runtime
	88.20   s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'Theta', 'RecursiveTabular', 'TemporalFusionTransformer']
Total runtime: 3676.14 s
Best model: RecursiveTabular
Best model score: -0.2741
Model not specified in predict, will default to the model with the best validation score: RecursiveTabular