Beginning AutoGluon training... Time limit = 9000s
AutoGluon will save models to 'AutogluonModels\ag-20240427_042301'
=================== System Info ===================
AutoGluon Version:  1.0.0
Python Version:     3.10.13
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.59 GB / 5.92 GB (9.9%)
Disk Space Avail:   10.84 GB / 118.01 GB (9.2%)
===================================================
Setting presets to: high_quality

Fitting with arguments:
{'enable_ensemble': False,
 'eval_metric': MSE,
 'hyperparameters': {'TemporalFusionTransformer': {}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'target': 'target',
 'time_limit': 9000,
 'verbosity': 2}

Inferred time series frequency: 'QS-OCT'
Provided train_data has 2214108 rows, 24000 time series. Median time series length is 88 (min=16, max=866). 
	Removing 13678 short time series from train_data. Only series with length >= 97 will be used for training.
	After removing short series, train_data has 1359498 rows, 10322 time series. Median time series length is 118 (min=97, max=866). 

Provided dataset contains following columns:
	target:           'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MSE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2024-04-27 07:23:04
Models that will be trained: ['TemporalFusionTransformer']
Training timeseries model TemporalFusionTransformer. Training for up to 8997.3s of the 8997.3s of remaining time.
	-7595825.2688 = Validation score (-MSE)
	6124.34 s     = Training runtime
	90.09   s     = Validation (prediction) runtime
Training complete. Models trained: ['TemporalFusionTransformer']
Total runtime: 6214.64 s
Best model: TemporalFusionTransformer
Best model score: -7595825.2688
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer